{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exploring Hacker news posts\n",
    "We analyse a dataset consisting of 20,000 posts on the Hacker News website.  Each post is classified as an *Ask HN* or a *Show HN* post.  Our goal is to find out which post receive more comments on average.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import the data from the file `hacker_news.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "open_file = open('hacker_news.csv')\n",
    "read_file = reader(open_file)\n",
    "hn = list(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the row containing the column titles and keep only the data in the variable `data_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = hn[0]\n",
    "hn = hn[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display the headers and print the first five rows of the dataset `hacker_news.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']\n"
     ]
    }
   ],
   "source": [
    "print(headers)\n",
    "for row in hn[:5]:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting the data and calculating the average number of comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create three empty lists `ask_posts`, `show_posts`, `other_posts` that will contain the posts starting with *Ask HN*, *Show HN*, and the remaining ones, repectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_posts, show_posts, other_posts = [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build each of these lists with a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the number of posts for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the average number of comments for both the *Ask HN* and the *Show HN* post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of comments per Ask HN posts is 14.04\n",
      "The average number of comments per Show HN posts is 10.32\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for row in ask_posts:\n",
    "    total_ask_comments += int(row[4])\n",
    "\n",
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    total_show_comments += int(row[4])\n",
    "\n",
    "average_ask_comments = total_ask_comments/len(ask_posts)\n",
    "average_show_comments = total_show_comments/len(show_posts)\n",
    "\n",
    "print(\"The average number of comments per Ask HN posts is {:.2f}\".format(average_ask_comments))\n",
    "print(\"The average number of comments per Show HN posts is {:.2f}\".format(average_show_comments))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, the *Ask HN* posts received more comments than the *Show HN* posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the average number of comments for the *Ask HN* posts per hour created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the datetime module for that purpose, and we collect the needed data for that purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    two_data = [row[6],int(row[4])]\n",
    "    result_list.append(two_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the number of posts created at a given time as well as the corresponding number of comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'09': 251, '13': 1253, '10': 793, '14': 1416, '16': 1814, '23': 543, '12': 687, '17': 1146, '15': 4477, '21': 1745, '20': 1722, '02': 1381, '18': 1439, '03': 421, '05': 464, '19': 1188, '01': 683, '22': 479, '08': 492, '04': 337, '00': 447, '06': 397, '07': 267, '11': 641}\n"
     ]
    }
   ],
   "source": [
    "counts_per_hour = {}\n",
    "comments_per_hour = {}\n",
    "data_format = \"%m/%d/%Y %H:%M\"\n",
    "\n",
    "for data in result_list:\n",
    "    hour = dt.datetime.strptime(data[0],data_format).strftime(\"%H\")\n",
    "    if hour in counts_per_hour:\n",
    "        counts_per_hour[hour] += 1\n",
    "        comments_per_hour[hour] += data[1]\n",
    "    else:\n",
    "        counts_per_hour[hour] = 1\n",
    "        comments_per_hour[hour] = data[1]\n",
    "        \n",
    "print(comments_per_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the average number of comments per post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['09', 5.5777777777777775]\n",
      "['13', 14.741176470588234]\n",
      "['10', 13.440677966101696]\n",
      "['14', 13.233644859813085]\n",
      "['16', 16.796296296296298]\n",
      "['23', 7.985294117647059]\n",
      "['12', 9.41095890410959]\n",
      "['17', 11.46]\n",
      "['15', 38.5948275862069]\n",
      "['21', 16.009174311926607]\n",
      "['20', 21.525]\n",
      "['02', 23.810344827586206]\n",
      "['18', 13.20183486238532]\n",
      "['03', 7.796296296296297]\n",
      "['05', 10.08695652173913]\n",
      "['19', 10.8]\n",
      "['01', 11.383333333333333]\n",
      "['22', 6.746478873239437]\n",
      "['08', 10.25]\n",
      "['04', 7.170212765957447]\n",
      "['00', 8.127272727272727]\n",
      "['06', 9.022727272727273]\n",
      "['07', 7.852941176470588]\n",
      "['11', 11.051724137931034]\n"
     ]
    }
   ],
   "source": [
    "avg_per_hour = []\n",
    "\n",
    "for item in counts_per_hour:\n",
    "    ave = comments_per_hour[item]/counts_per_hour[item]\n",
    "    avg_per_hour.append([item,ave])\n",
    "    \n",
    "for x in avg_per_hour:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the last part of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.5777777777777775, '09'], [14.741176470588234, '13'], [13.440677966101696, '10'], [13.233644859813085, '14'], [16.796296296296298, '16'], [7.985294117647059, '23'], [9.41095890410959, '12'], [11.46, '17'], [38.5948275862069, '15'], [16.009174311926607, '21'], [21.525, '20'], [23.810344827586206, '02'], [13.20183486238532, '18'], [7.796296296296297, '03'], [10.08695652173913, '05'], [10.8, '19'], [11.383333333333333, '01'], [6.746478873239437, '22'], [10.25, '08'], [7.170212765957447, '04'], [8.127272727272727, '00'], [9.022727272727273, '06'], [7.852941176470588, '07'], [11.051724137931034, '11']]\n"
     ]
    }
   ],
   "source": [
    "swap_ave_per_hour = []\n",
    "\n",
    "for item in avg_per_hour:\n",
    "    swap_ave_per_hour.append([item[1],item[0]])\n",
    "    \n",
    "print(swap_ave_per_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38.5948275862069, '15']\n",
      "[23.810344827586206, '02']\n",
      "[21.525, '20']\n",
      "[16.796296296296298, '16']\n",
      "[16.009174311926607, '21']\n",
      "[14.741176470588234, '13']\n",
      "[13.440677966101696, '10']\n",
      "[13.233644859813085, '14']\n",
      "[13.20183486238532, '18']\n",
      "[11.46, '17']\n",
      "[11.383333333333333, '01']\n",
      "[11.051724137931034, '11']\n",
      "[10.8, '19']\n",
      "[10.25, '08']\n",
      "[10.08695652173913, '05']\n",
      "[9.41095890410959, '12']\n",
      "[9.022727272727273, '06']\n",
      "[8.127272727272727, '00']\n",
      "[7.985294117647059, '23']\n",
      "[7.852941176470588, '07']\n",
      "[7.796296296296297, '03']\n",
      "[7.170212765957447, '04']\n",
      "[6.746478873239437, '22']\n",
      "[5.5777777777777775, '09']\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_ave_per_hour,reverse=True)\n",
    "for item in sorted_swap:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38.5948275862069, '15']\n",
      "[23.810344827586206, '02']\n",
      "[21.525, '20']\n",
      "[16.796296296296298, '16']\n",
      "[16.009174311926607, '21']\n"
     ]
    }
   ],
   "source": [
    "for x in range(5):\n",
    "    print(sorted_swap[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the highest five averages in a nicer format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "for item in range(5):\n",
    "    formatted_hour = dt.datetime.strptime(sorted_swap[item][1],\"%H\").strftime(\"%H:%M\")\n",
    "    print(\"{}: {:.2f} average comments per post\".format(formatted_hour,sorted_swap[item][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this data, one should post her *Ask HN* post around 3pm to receive the most number of comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait a second, can I write some latex code in here such as\n",
    "$$\\int_{x=1}^{2}f(x) \\, dx $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow!  This is so awesome.  Let's say with have a $\\mathbb{Z}_{\\ell}$-tower of graphs\n",
    "\n",
    "$$X = X_{0} \\leftarrow X_{1} \\leftarrow X_{2} \\leftarrow \\ldots \\leftarrow X_{n} \\leftarrow \\ldots  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has really good potential I think for my Math 217 class!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter Lab is supposed to be better a bit than Jypyter Notebook, but I am not quite sure why.  In any case, this feature of combining Latex with codes and plain Markup text is pretty awesome, I think.\n",
    "\n",
    "$$\\sum_{n=1}^{\\infty}\\left(\\frac{1}{2} \\right)^{n} $$\n",
    "\n",
    "I wonder what else can be done with a Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
